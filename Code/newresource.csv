AlgorithmID,AlgorithmName,EnglishName,ParentCategory,AlgorithmType,TimeComplexity,SpaceComplexity,Stability,UseCases,CoreIdea,ApplicableDomains,ProsConsAnalysis
A001,冒泡排序,Bubble Sort,排序,比较排序,O(n^2),O(1),稳定,小规模数据排序;教学示例,重复遍历待排序的列表，比较相邻的两个元素，如果顺序错误就交换它们。遍历列表的工作是重复地进行直到没有再需要交换，也就是说该列表已经排序完成。每一次遍历至少会将一个元素（最大或最小）放到其最终位置。,计算机科学;软件工程,优点：算法思想简单，易于理解和实现，代码量少。缺点：时间复杂度高，效率低下，不适合大规模数据排序。在所有排序算法中，冒泡排序的性能是最差的之一，尤其是在数据量较大时，其O(n^2)的平均和最坏时间复杂度使其变得非常慢，实际应用中很少使用。
A002,选择排序,Selection Sort,排序,比较排序,O(n^2),O(1),不稳定,小规模数据排序;教学示例,在未排序的序列中找到最小（或最大）元素，存放到排序序列的起始位置，然后再从剩余未排序元素中继续寻找最小（或最大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。,计算机科学;软件工程,优点：实现简单，空间复杂度为O(1)，对数据移动次数少（最多n-1次）。缺点：时间复杂度高，无论是最好、最坏还是平均情况，都是O(n^2)，不适合处理大规模数据。其性能在所有O(n^2)排序算法中相对稳定，但整体效率不高。
A003,插入排序,Insertion Sort,排序,比较排序,O(n^2),O(1),稳定,小规模数据排序;基本有序数据排序,通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。就像玩扑克牌时，每次摸到一张牌，就把它插入到手中已有的牌的正确位置。,计算机科学;软件工程,优点：对于小规模数据或基本有序的数据，效率较高（接近O(n)），且是稳定的排序算法，空间复杂度为O(1)，实现简单。缺点：对于大规模的乱序数据，其O(n^2)的时间复杂度使其效率低下。
A004,快速排序,Quick Sort,排序,比较排序;分治,平均O(n log n)，最坏O(n^2),平均O(log n)，最坏O(n) (递归栈空间),不稳定,大规模数据排序;内部排序,采用分治策略。它选择一个元素作为“基准”（pivot），然后将数组分成两部分：一部分是所有小于基准的元素，另一部分是所有大于基准的元素。对这两部分递归地进行快速排序，直到整个数组有序。核心在于分区操作，使得基准元素处于其最终的有序位置。,计算机科学;软件工程;算法竞赛,优点：平均时间复杂度为O(n log n)，在实际应用中通常表现良好，是效率最高的通用排序算法之一，常用于大规模数据的排序。缺点：最坏情况下时间复杂度为O(n^2)，发生在输入数据已经有序或接近有序，且选择的基准不当（如总是选择最小或最大元素）时。快速排序是不稳定的排序算法，即相等元素的相对顺序可能会改变。
A005,归并排序,Merge Sort,排序,比较排序;分治,O(n log n),O(n),稳定,大规模数据排序;外部排序;并行排序,将序列递归地分成两半，直到每个子序列只有一个元素（自然有序）。然后，将这些子序列两两合并，每次合并都将两个有序的子序列合并成一个更大的有序子序列，直到所有元素合并成一个完整的有序序列。合并操作是其核心，通过比较两个子序列的元素并按顺序放入新数组实现。,计算机科学;软件工程;大数据处理,优点：时间复杂度稳定为O(n log n)，无论是最好、最坏还是平均情况，都保持高效。它是稳定的排序算法，适合处理大规模数据，且易于并行化。缺点：需要额外的O(n)空间来存储合并过程中的临时数组，这在内存受限的环境下可能成为瓶颈。
A006,堆排序,Heap Sort,排序,比较排序,O(n log n),O(1),不稳定,大规模数据排序;优先级队列实现,利用堆这种数据结构来排序。首先将待排序序列构造成一个大顶堆（或小顶堆），此时堆顶元素是最大（或最小）值。然后将堆顶元素与堆的最后一个元素交换，将最大（或最小）元素“沉”到数组末尾。接着对剩余的n-1个元素重新调整为堆，重复此过程，直到所有元素排序完毕。,计算机科学;软件工程;数据结构,优点：时间复杂度稳定为O(n log n)，且空间复杂度为O(1)，是一种原地排序算法，效率较高。缺点：堆排序是不稳定的排序算法。在实际应用中，由于其常数因子较大，通常比快速排序慢，且对缓存不友好。
A007,计数排序,Counting Sort,排序,非比较排序,O(n+k),O(k),稳定,整数排序;小范围整数排序,对输入数据进行计数，将每个元素出现的次数存放在一个辅助数组中，然后根据辅助数组中存储的次数，将数据按顺序输出到结果数组中。适用于整数且范围不大的数据。,计算机科学;数据处理,优点：当待排序的整数范围k不大时，时间复杂度为O(n+k)，效率非常高，是线性时间排序。它是稳定的排序算法。缺点：只能用于整数排序，且当整数范围k非常大时，需要大量的额外空间，不适合处理浮点数或字符串。
A008,桶排序,Bucket Sort,排序,非比较排序,平均O(n+k)，最坏O(n^2),O(n+k),稳定,浮点数排序;数据均匀分布的排序,将待排序的数据分到有限数量的桶里，每个桶再分别排序（可以使用其他排序算法），最后将所有桶中的数据依次取出，形成有序序列。适用于数据均匀分布的情况。,计算机科学;大数据处理,优点：当输入数据均匀分布时，平均时间复杂度可以达到O(n+k)，效率很高。它是稳定的排序算法。缺点：对数据的分布情况有要求，如果数据分布不均匀，可能导致某些桶中数据过多，退化为O(n^2)。需要额外的空间来存储桶。
A009,基数排序,Radix Sort,排序,非比较排序,O(nk),O(n+k),稳定,多位数整数排序;字符串排序,将整数按位数切割成不同的数字，然后从最低位到最高位依次进行排序。每次排序都使用一个稳定的排序算法（如计数排序）对当前位进行排序。适用于整数或可以表示为整数的数据。,计算机科学;数据处理,优点：时间复杂度为O(nk)，当k（位数）较小时，效率非常高，是线性时间排序。它是稳定的排序算法。缺点：只能用于整数或可以表示为整数的数据。需要额外的空间来存储中间结果，且实现相对复杂。
A010,线性查找,Linear Search,搜索,顺序搜索,O(n),O(1),不适用,无序数据查找;小规模数据查找,从数据序列的第一个元素开始，逐个与目标值进行比较，直到找到目标值或遍历完整个序列。如果找到则返回其位置，否则表示未找到。,计算机科学;软件工程,优点：算法简单，易于实现，对数据结构没有要求，适用于任何无序或有序的序列。缺点：效率低下，时间复杂度为O(n)，对于大规模数据查找效率极低，不适合大数据量的场景。
A011,二分查找,Binary Search,搜索,分治搜索,O(log n),O(1),不适用,有序数据查找;字典查询;查找特定值,适用于有序数组。每次查找都通过比较中间元素与目标值，将查找范围缩小一半。如果中间元素等于目标值，则查找成功；如果目标值小于中间元素，则在左半部分继续查找；如果目标值大于中间元素，则在右半部分继续查找，直到找到或查找范围为空。,计算机科学;软件工程;数据库查询,优点：效率高，时间复杂度为O(log n)，对于大规模有序数据查找非常快。缺点：要求数据必须是有序的，且只能在顺序存储结构（如数组）上进行操作，对链表等不适用。插入和删除操作会破坏有序性，需要重新排序。
A012,深度优先搜索,DFS,图算法,图遍历,O(V+E),O(V),不适用,图遍历;路径查找;连通性判断;拓扑排序,从图中某个顶点V出发，访问此顶点，然后依次从V的未被访问的邻接点出发，深度优先遍历图，直到图中所有和V有路径相通的顶点都被访问到。如果图中还有未被访问的顶点，则选择其中一个作为起始点，重复上述过程。核心思想是“不撞南墙不回头”。,计算机科学;图论;人工智能,优点：实现简单，可以找到所有连通的顶点。适用于寻找路径、判断连通性等。缺点：不保证找到最短路径。对于大规模图，递归深度可能过大导致栈溢出。
A013,广度优先搜索,BFS,图算法,图遍历,O(V+E),O(V),不适用,图遍历;最短路径查找(无权图);网络爬虫;社交网络分析,从图中某个顶点V出发，先访问其所有邻接点，再依次访问这些邻接点的所有未被访问的邻接点，以此类推，逐层向外扩展，直到所有可达顶点都被访问。核心思想是“层层推进”。,计算机科学;图论;人工智能;网络,优点：能够找到无权图中的最短路径。实现简单，通常使用队列来辅助实现，避免了深度优先搜索可能出现的栈溢出问题。缺点：需要额外的空间来存储队列。对于某些问题，可能需要遍历更多的节点才能找到目标。
A014,Dijkstra算法,Dijkstra's Algorithm,图算法,最短路径,O(E log V) 或 O(V^2),O(V),不适用,单源最短路径(非负权);网络路由;地图导航,用于计算从图中一个顶点到所有其他顶点的最短路径，前提是边的权重是非负的。它维护一个顶点集合，这些顶点的最短路径已经被确定。每次迭代从剩余顶点中选择一个距离源点最近的顶点，并更新其邻接点的距离。,计算机科学;图论;网络路由;地理信息系统,优点：能够正确计算出单源最短路径，且算法思想直观易懂。对于非负权图，效率较高。缺点：不能处理负权边。对于边数E远大于顶点数V的稠密图，效率可能不如Bellman-Ford算法。
A015,Floyd-Warshall算法,Floyd-Warshall Algorithm,图算法,最短路径,O(V^3),O(V^2),不适用,所有顶点对最短路径;交通规划;旅行商问题变种,用于计算图中所有顶点对之间的最短路径。它通过动态规划的思想，逐步考虑所有可能的中间顶点，来更新任意两点之间的最短路径。算法的核心在于三重循环，外层循环遍历中间顶点，内层循环遍历起始点和终止点。,计算机科学;图论;运筹学,优点：能够处理带负权边的图（但不处理负权环）。算法简洁，易于实现。可以找到所有顶点对之间的最短路径。缺点：时间复杂度为O(V^3)，对于大规模图效率较低。空间复杂度为O(V^2)。
A016,Prim算法,Prim's Algorithm,图算法,最小生成树,O(E log V) 或 O(V^2),O(V),不适用,最小生成树;网络设计;电路布线,从一个起始顶点开始，逐步添加边来构建最小生成树。每次选择一条连接树中顶点和树外顶点，且权重最小的边，并将其对应的树外顶点加入到树中，直到所有顶点都被包含在树中。它类似于Dijkstra算法，但目的是找到最小生成树而不是最短路径。,计算机科学;图论;网络设计,优点：能够正确找到连通图的最小生成树。对于稠密图（边数多）效率较高（使用邻接矩阵实现时）。缺点：对于稀疏图（边数少），Kruskal算法通常更优。
A017,Kruskal算法,Kruskal's Algorithm,图算法,最小生成树,O(E log E) 或 O(E log V),O(V+E),不适用,最小生成树;网络设计;电路布线,将图中所有边按权重从小到大排序，然后依次遍历每条边。如果当前边连接的两个顶点不在同一个连通分量中，则将这条边加入到最小生成树中，并合并这两个连通分量。直到生成树包含V-1条边。通常使用并查集来判断和合并连通分量。,计算机科学;图论;网络设计,优点：能够正确找到连通图的最小生成树。对于稀疏图（边数少）效率较高。算法思想相对直观，易于理解。缺点：需要对边进行排序，对于边数非常多的图，排序可能耗时。
A018,拓扑排序,Topological Sort,图算法,图遍历,O(V+E),O(V),不适用,任务调度;课程安排;依赖解决,对有向无环图（DAG）的顶点进行线性排序，使得对于每条有向边(u，v)，顶点u都在顶点v之前。通常有两种实现方式：Kahn算法（基于入度）和DFS算法（基于深度优先遍历）。,计算机科学;图论;项目管理;编译器设计,优点：能够解决有向无环图中的依赖关系问题，确保任务按正确的顺序执行。缺点：只能应用于有向无环图，对于有环图无法进行拓扑排序。结果可能不唯一。
A019,Bellman-Ford算法,Bellman-Ford Algorithm,图算法,最短路径,O(VE),O(V),不适用,单源最短路径(含负权);负权环检测,用于计算从单个源点到所有其他顶点的最短路径，可以处理边的权重为负数的情况。它通过V-1次迭代，每次迭代都尝试对所有边进行松弛操作，以逐步找到最短路径。如果在第V次迭代时仍能进行松弛，则说明图中存在负权环。,计算机科学;图论;网络路由,优点：能够正确处理含有负权边的图，并且可以检测出负权环。缺点：时间复杂度为O(VE)，比Dijkstra算法慢，对于大规模图效率较低。
A020,A*搜索算法,A* Search Algorithm,搜索,启发式搜索;图遍历,O(E) (取决于启发函数),O(V),不适用,路径规划;游戏AI;机器人导航,A*算法是一种启发式搜索算法，用于在图中找到从起点到终点的最短路径。它结合了Dijkstra算法（保证找到最短路径）和贪婪最佳优先搜索（利用启发式信息加速搜索）。它通过评估函数 $f(n) = g(n) + h(n)$ 来选择下一个要扩展的节点，其中$g(n)$是从起点到当前节点的实际代价，$h(n)$是从当前节点到目标节点的估计代价（启发式函数）。,计算机科学;人工智能;游戏开发;机器人学,优点：在许多实际应用中比Dijkstra算法效率更高，因为它利用启发式信息来指导搜索方向，通常能更快地找到最短路径。如果启发式函数是可接受的（Admissible）且一致的（Consistent），A*算法能保证找到最优解。缺点：启发式函数的选择至关重要，不好的启发式函数可能导致性能下降甚至退化为Dijkstra或BFS。需要存储已访问节点，可能占用大量内存。
A021,KMP算法,KMP Algorithm,字符串,模式匹配,O(m+n),O(m),不适用,字符串查找;文本编辑器的查找功能,Knuth-Morris-Pratt算法是一种字符串匹配算法。它通过预处理模式串（构建一个部分匹配表，也称作next数组），在匹配过程中当出现不匹配时，可以利用已经匹配过的信息，避免模式串指针回溯，从而提高效率。核心思想是利用模式串自身的特性，避免不必要的比较。,计算机科学;文本处理;生物信息学,优点：时间复杂度为O(m+n)，是线性时间复杂度，效率高，优于朴素的字符串匹配算法。避免了主串指针的回溯，提高了匹配效率。缺点：算法理解和实现相对复杂，需要预处理模式串。
A022,Rabin-Karp算法,Rabin-Karp Algorithm,字符串,模式匹配,平均O(m+n)，最坏O(mn),O(m),不适用,字符串查找;文本编辑器的查找功能;剽窃检测,Rabin-Karp算法是一种基于哈希的字符串匹配算法。它通过计算模式串和文本串中每个子串的哈希值，然后比较哈希值来判断是否匹配。当哈希值匹配时，再进行一次字符级别的比较以避免哈希冲突。核心思想是滚动哈希，高效地计算每个子串的哈希值。,计算机科学;文本处理;信息检索,优点：平均时间复杂度为O(m+n)，在实际应用中效率较高。易于扩展到多模式匹配。缺点：最坏情况下时间复杂度可能退化到O(mn)，当哈希冲突频繁发生时。需要选择合适的哈希函数和模数来减少冲突。
A023,Boyer-Moore算法,Boyer-Moore Algorithm,字符串,模式匹配,平均O(n/m)，最坏O(mn),O(字符集大小),不适用,字符串查找;文本编辑器的查找功能,Boyer-Moore算法是一种高效的字符串匹配算法。它从模式串的末尾开始与文本串进行比较，当出现不匹配时，根据“坏字符规则”和“好后缀规则”尽可能大地向右移动模式串，从而跳过不必要的比较。核心思想是利用不匹配信息进行大步跳跃。,计算机科学;文本处理;信息检索,优点：在实际应用中通常比KMP算法更快，平均时间复杂度接近O(n/m)，效率非常高。缺点：最坏情况下时间复杂度为O(mn)。算法理解和实现相对复杂。
A024,Manacher算法,Manacher's Algorithm,字符串,模式匹配,O(n),O(n),不适用,最长回文子串查找,Manacher算法用于在线性时间内找到一个字符串中的最长回文子串。它通过预处理字符串（插入特殊字符以处理奇偶长度回文串），然后利用回文串的对称性，避免重复计算，从而达到线性时间复杂度。核心思想是利用已计算的回文半径，跳过不必要的比较。,计算机科学;字符串处理,优点：时间复杂度为O(n)，是线性时间算法，非常高效。能够处理所有情况（奇数和偶数长度回文串）。缺点：算法理解和实现相对复杂，需要对字符串进行预处理。
A025,Z算法,Z-Algorithm,字符串,模式匹配,O(n+m),O(n+m),不适用,字符串匹配;模式匹配;LCP数组构建,Z算法（也称为Z-box算法）用于计算一个字符串S的Z数组。Z数组$Z[i]$表示S和S的后缀$S[i..]$的最长公共前缀的长度。通过计算Z数组，可以高效地进行字符串匹配。核心思想是利用已经计算的Z值，避免重复比较，实现线性时间复杂度。,计算机科学;字符串处理;文本分析,优点：时间复杂度为O(n+m)，是线性时间算法，非常高效。可以用于解决字符串匹配问题，比KMP更易于理解和实现。缺点：相对KMP，其应用场景可能更专注于LCP（最长公共前缀）的计算，但同样可以解决模式匹配。
A026,最长公共子序列,Longest Common Subsequence (LCS),动态规划,序列比对,O(mn),O(mn),不适用,DNA序列比对;文件差异比较;版本控制,LCS算法通过动态规划来解决。它构建一个二维DP表，其中$DP[i][j]$表示字符串A的前i个字符和字符串B的前j个字符的最长公共子序列的长度。通过比较字符，并根据匹配或不匹配的情况，从前一个子问题的解推导出当前子问题的解。,计算机科学;生物信息学;文本处理,优点：能够找到两个序列的最长公共子序列，在许多领域有广泛应用。缺点：时间复杂度为O(mn)，空间复杂度也为O(mn)，对于非常长的序列可能效率较低或内存消耗大。
A027,0/1背包问题,0/1 Knapsack Problem,动态规划,优化问题,O(nW),O(nW) 或 O(W),不适用,资源分配;物品选择;投资组合优化,给定一组物品，每种物品都有自己的重量和价值，在限定的总重量内，选择其中一部分物品，使得总价值最大。0/1背包问题意味着每种物品只能选择一次（0或1）。通过动态规划构建DP表，$DP[i][w]$表示前i个物品在容量为w时的最大价值。,计算机科学;运筹学;算法竞赛,优点：能够找到最优解。动态规划方法思路清晰，易于理解和实现。缺点：时间复杂度为O(nW)，其中W是背包容量，当W非常大时，效率会很低。属于NP-hard问题，动态规划是伪多项式时间解法。
A028,完全背包问题,Unbounded Knapsack Problem,动态规划,优化问题,O(nW),O(nW) 或 O(W),不适用,资源分配;物品选择;找零钱问题,与0/1背包问题类似，但每种物品可以无限次选择。动态规划的递推关系略有不同，允许从当前物品再次选择。$DP[w]$表示容量为w时的最大价值，在计算$DP[w]$时，可以考虑多次选择同一个物品。,计算机科学;运筹学;算法竞赛,优点：能够找到最优解。适用于物品可以重复选择的场景。缺点：时间复杂度为O(nW)，当W非常大时，效率会很低。
A029,最长递增子序列,Longest Increasing Subsequence (LIS),动态规划,序列问题,O(n log n) 或 O(n^2),O(n),不适用,序列分析;数据挖掘;生物信息学,LIS算法的目标是找到一个序列中最长的严格递增的子序列。可以通过动态规划实现，其中$DP[i]$表示以第i个元素结尾的最长递增子序列的长度。更优的O(n log n)方法利用二分查找来维护一个最小末尾元素数组。,计算机科学;数据分析;算法竞赛,优点：能够找到序列中的最长递增子序列。O(n log n)的方法效率较高。缺点：O(n^2)的方法对于大规模数据效率较低。
A030,编辑距离,Edit Distance (Levenshtein Distance),动态规划,序列比对;字符串相似度,O(mn),O(mn) 或 O(min(m，n)),不适用,拼写检查;基因序列比对;自然语言处理,编辑距离（或Levenshtein距离）是衡量两个字符串之间相似度的一种指标，表示将一个字符串转换成另一个字符串所需的最少单字符编辑操作（插入、删除或替换）的次数。通过动态规划构建DP表，$DP[i][j]$表示第一个字符串的前i个字符和第二个字符串的前j个字符之间的编辑距离。,计算机科学;自然语言处理;生物信息学,优点：能够准确衡量字符串之间的相似度，在许多文本处理任务中非常有用。缺点：时间复杂度为O(mn)，空间复杂度也为O(mn)，对于非常长的字符串可能效率较低或内存消耗大。
A031,矩阵链乘法,Matrix Chain Multiplication,动态规划,优化问题,O(n^3),O(n^2),不适用,矩阵运算优化,给定一系列矩阵，找出一种乘法顺序，使得总的乘法次数最少。矩阵乘法满足结合律但不满足交换律。通过动态规划，将问题分解为子问题，计算每个子链的最优乘法次数，并存储结果以避免重复计算。,计算机科学;线性代数;数值计算,优点：能够找到矩阵链乘法的最优顺序，显著减少计算量。缺点：时间复杂度为O(n^3)，其中n是矩阵的数量，对于大量矩阵的链乘效率较低。
A032,最长回文子串,Longest Palindromic Substring,动态规划,字符串处理,O(n^2),O(n^2),不适用,文本处理;生物信息学,通过动态规划，定义$DP[i][j]$为布尔值，表示从索引i到j的子串是否为回文串。如果$S[i] == S[j]$且$DP[i+1][j-1]$为真，则$DP[i][j]$为真。遍历所有可能的子串，并记录最长的回文子串。,计算机科学;字符串处理,优点：能够找到字符串中的最长回文子串。动态规划方法思路清晰。缺点：时间复杂度为O(n^2)，空间复杂度为O(n^2)，对于长字符串效率较低。Manacher算法可以达到O(n)时间复杂度。
A033,背包问题,Knapsack Problem (General),动态规划,优化问题,O(nW),O(nW),不适用,资源分配;项目选择;组合优化,一个通用的概念，包含0/1背包、完全背包、多重背包等变种。核心思想是给定一组物品，每件物品有重量和价值，目标是在不超过背包容量的前提下，使装入背包的物品总价值最大。,计算机科学;运筹学;算法竞赛,优点：能够解决多种资源分配和优化问题，找到最优解。动态规划是解决这类问题的标准方法。缺点：通常具有伪多项式时间复杂度，当背包容量或物品数量非常大时，计算成本高昂。
A034,最长公共子串,Longest Common Substring,动态规划,字符串相似度,O(mn),O(mn),不适用,文本相似度;DNA序列比对,与最长公共子序列不同，子串要求字符在原字符串中是连续的。通过动态规划，定义$DP[i][j]$为以$S1[i]$和$S2[j]$结尾的最长公共子串的长度。如果$S1[i] == S2[j]$，则$DP[i][j] = DP[i-1][j-1] + 1$，否则为0。记录DP表中的最大值。,计算机科学;字符串处理;生物信息学,优点：能够找到两个字符串中的最长公共子串。缺点：时间复杂度为O(mn)，空间复杂度为O(mn)，对于长字符串效率较低。
A035,区间DP,Interval Dynamic Programming,动态规划,区间问题,O(n^3),O(n^2),不适用,石子合并;括号匹配;最优二叉搜索树,区间DP通常用于解决与区间相关的优化问题。其核心思想是将一个大区间的问题分解为更小的子区间问题，然后通过子问题的解来推导大问题的解。通常采用枚举分割点的方式进行状态转移。,计算机科学;算法竞赛,优点：能够解决一类具有最优子结构和重叠子问题的区间优化问题。缺点：通常时间复杂度较高，为O(n^3)，空间复杂度为O(n^2)。
A036,数位DP,Digit Dynamic Programming,动态规划,计数问题,O(log N * K),O(log N * K),不适用,统计满足特定条件的数字个数,数位DP用于解决在一给定区间$[L，R]$内，统计满足某种性质的数字的个数。它将数字按位分解，通过DP状态来记录当前位、是否达到上限、是否包含前导零等信息，从而避免重复计算。核心思想是记忆化搜索或迭代DP。,计算机科学;算法竞赛,优点：能够高效解决特定区间内数字计数问题，避免暴力枚举。缺点：状态定义和转移相对复杂，需要仔细考虑边界条件和各种状态。
A037,状态压缩DP,State Compression Dynamic Programming,动态规划,组合优化,O(N * 2^N * M),O(N * 2^N),不适用,旅行商问题;TSP;哈密顿回路;集合覆盖,当问题的状态可以用一个二进制数（位运算）来表示时，可以使用状态压缩DP。例如，旅行商问题中，一个二进制数可以表示已经访问过的城市集合。DP状态通常包含当前位置和已访问状态。,计算机科学;算法竞赛;组合优化,优点：能够解决一些NP-hard问题的特定规模实例，将指数级的搜索空间通过DP优化。缺点：时间复杂度和空间复杂度都与$2^N$相关，因此N不能太大（通常N<20）。
A038,树形DP,Tree Dynamic Programming,动态规划,树结构问题,O(N) 或 O(N log N),O(N),不适用,树的最大独立集;树的直径;树的重心,树形DP是应用于树结构上的动态规划。它利用树的递归性质，从叶子节点向根节点（或从根节点向叶子节点）进行状态转移，通常通过DFS遍历计算子树的信息，然后合并到父节点。常见的状态定义包括以当前节点为根的子树的信息。,计算机科学;算法竞赛;网络拓扑分析,优点：能够高效解决树结构上的优化和计数问题，时间复杂度通常为O(N)。缺点：需要对树的遍历和状态转移有深入理解，状态定义可能比较灵活。
A039,期望DP,Expected Value Dynamic Programming,动态规划,概率问题,O(N*M),O(N*M),不适用,概率游戏;随机过程分析,期望DP用于计算某种随机过程的期望值。DP状态通常表示在某个状态下，达到目标状态的期望步数或期望收益。状态转移方程涉及概率和期望的计算，通常是倒序推导（从目标状态推向初始状态）。,计算机科学;概率论;算法竞赛,优点：能够解决涉及概率和期望的复杂问题。缺点：状态定义和转移方程的推导相对复杂，需要扎实的概率论基础。
A040,回溯算法,Backtracking Algorithm,搜索,组合问题,指数级,O(N) (递归栈),不适用,组合问题;排列问题;子集问题;N皇后问题;数独求解,回溯算法是一种通过探索所有可能的候选解来找出所有的解的算法。当算法在搜索过程中发现当前路径不可能达到目标时，就“回溯”到上一步，尝试另一条路径。它是一种深度优先遍历思想的应用，通常用递归实现。,计算机科学;人工智能;组合优化,优点：能够找到所有可能的解，或找到满足条件的第一个解。适用于解决组合、排列、子集等问题。缺点：时间复杂度通常是指数级的，对于大规模问题效率极低。需要剪枝操作来优化性能。
A041,贪心算法,Greedy Algorithm,优化问题,局部最优,多变,多变,不适用,活动选择问题;霍夫曼编码;最小生成树(Kruskal，Prim),在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是全局最好或最优的算法。它不考虑后续步骤的影响，只关注当前局部最优解。,计算机科学;运筹学;算法竞赛,优点：算法简单，易于实现，效率通常较高。在某些问题上能够找到全局最优解。缺点：不一定能找到全局最优解，只有当问题具有“贪心选择性质”和“最优子结构性质”时才能保证正确性。需要证明其正确性。
A042,分治算法,Divide and Conquer Algorithm,通用算法范式,递归,多变,多变,不适用,归并排序;快速排序;大整数乘法;最近点对问题,将一个大规模问题分解为若干个规模较小的相同子问题，对这些子问题进行求解，然后将子问题的解合并，得到原问题的解。通常采用递归实现。,计算机科学;算法设计,优点：能够将复杂问题分解为更易于管理和解决的子问题。许多高效算法都基于分治思想。易于并行化。缺点：递归实现可能导致额外的空间开销（栈空间）。子问题的划分和合并需要仔细设计。
A043,蒙特卡罗方法,Monte Carlo Method,随机算法,数值计算;模拟,多变,多变,不适用,积分计算;金融建模;物理模拟;复杂系统行为预测,蒙特卡罗方法是一类通过随机采样或模拟来解决计算问题的方法。它利用随机数生成大量的样本，然后通过统计这些样本来估计问题的解。例如，通过在正方形内随机投点来估计圆周率。,计算机科学;统计学;金融;物理学,优点：适用于解决那些难以用确定性算法解决的问题，尤其是高维问题。易于实现，可以得到近似解。缺点：结果是概率性的，需要足够多的样本才能保证精度。收敛速度通常较慢，精度提高需要大量计算资源。
A044,拉斯维加斯算法,Las Vegas Algorithm,随机算法,优化问题;搜索,多变,多变,不适用,八皇后问题;素数测试(Miller-Rabin),拉斯维加斯算法是一种随机化算法，它总是能给出正确的结果，但运行时间是不确定的。它通过随机选择来寻找解，如果找不到，则重新尝试，直到找到为止。与蒙特卡罗算法不同，它不牺牲结果的正确性。,计算机科学;密码学;算法设计,优点：总是能给出正确答案。在某些情况下，其平均运行时间可能远优于确定性算法。缺点：运行时间不确定，最坏情况下可能非常慢。
A045,遗传算法,Genetic Algorithm (GA),优化算法,启发式搜索;仿生算法,多变,多变,不适用,组合优化;机器学习参数优化;工程设计,遗传算法是一种模拟自然选择和遗传机制的全局优化算法。它通过模拟生物进化过程中的选择、交叉（Crossover）和变异（Mutation）等操作，迭代地改进解的种群，最终收敛到最优解或近似最优解。适用于解决复杂的优化问题。,计算机科学;人工智能;机器学习;运筹学,优点：能够处理复杂的、非线性的、多模态的优化问题，不依赖于梯度信息。具有全局搜索能力，可以避免陷入局部最优。缺点：收敛速度可能较慢。参数选择（种群大小、交叉率、变异率等）对性能影响大，需要经验调整。不保证找到全局最优解，通常是近似最优解。
A046,模拟退火算法,Simulated Annealing (SA),优化算法,启发式搜索,多变,多变,不适用,组合优化;VLSI设计;图像处理,模拟退火算法是一种基于物理退火过程的启发式搜索算法，用于解决组合优化问题。它从一个随机初始解开始，通过随机扰动生成新解。与贪心算法不同，它以一定的概率接受较差的解，从而跳出局部最优，随着“温度”的降低，接受较差解的概率逐渐减小，最终收敛到全局最优解或近似最优解。,计算机科学;人工智能;机器学习;运筹学,优点：能够跳出局部最优，具有全局搜索能力。适用于解决复杂的组合优化问题，不依赖于梯度信息。缺点：收敛速度可能较慢。参数（初始温度、降温速率、迭代次数等）的选择对性能影响大，需要经验调整。不保证找到全局最优解。
A047,蚁群算法,Ant Colony Optimization (ACO),优化算法,启发式搜索;仿生算法,多变,多变,不适用,旅行商问题;路径规划;网络路由,蚁群算法是一种模拟蚂蚁觅食行为的启发式优化算法。蚂蚁在寻找食物时会释放信息素，其他蚂蚁会倾向于沿着信息素浓度高的路径前进。算法通过模拟信息素的积累和挥发过程，最终找到最优路径。适用于解决组合优化问题。,计算机科学;人工智能;机器学习;运筹学,优点：具有分布式计算的特点，鲁棒性强，能够处理动态问题。适用于解决旅行商问题等复杂的组合优化问题。缺点：收敛速度可能较慢。参数选择（信息素挥发率、信息素增加量等）对性能影响大。
A048,粒子群优化算法,Particle Swarm Optimization (PSO),优化算法,启发式搜索;仿生算法,多变,多变,不适用,函数优化;机器学习参数优化;图像处理,粒子群优化算法是一种模拟鸟群觅食行为的启发式优化算法。它将每个候选解看作一个在搜索空间中飞行的“粒子”，每个粒子根据其自身找到的最佳位置和整个群体找到的最佳位置来调整其飞行速度和位置，从而逐步逼近最优解。,计算机科学;人工智能;机器学习;优化,优点：算法简单，易于实现，参数较少。收敛速度相对较快。适用于解决连续函数优化问题。缺点：容易陷入局部最优，尤其是在高维复杂问题中。对参数选择敏感。
A049,支持向量机,Support Vector Machine (SVM),机器学习,分类;回归,训练O(n^2)到O(n^3),预测O(维度)，O(特征数),不适用,文本分类;图像识别;生物信息学,支持向量机是一种二分类模型，其基本思想是找到一个超平面，使得不同类别的样本点被最大间隔地分开。对于非线性可分数据，通过核函数（Kernel Function）将数据映射到高维空间，使其在高维空间中线性可分。核心是最大化分类间隔。,人工智能;机器学习;模式识别,优点：在处理小样本、非线性及高维模式识别问题中表现出许多特有的优势。泛化能力强，不易过拟合。缺点：对大规模数据集训练效率不高。对缺失数据敏感。核函数的选择和参数调整对性能影响大。多分类问题需要额外策略。
A055,逻辑回归,Logistic Regression,机器学习,分类,O(特征数^2 * 样本数) (迭代优化),O(特征数),不适用,二分类问题;疾病诊断;信用评分;垃圾邮件识别,逻辑回归是一种用于解决二分类问题的广义线性模型。它通过Sigmoid函数将线性回归的输出映射到[0，1]之间，表示属于某一类别的概率。模型的目标是最大化似然函数，通常使用梯度下降等优化算法来求解参数。,人工智能;机器学习;统计学;金融,优点：模型简单，易于理解和解释，计算效率高。输出是概率值，可解释性强。缺点：只能处理线性可分或近似线性可分的问题。对于非线性关系效果不佳。对特征工程要求较高。
A056,朴素贝叶斯分类器,Naive Bayes Classifier,机器学习,分类,训练O(样本数 * 特征数)，预测O(特征数),O(特征数 * 类别数),不适用,文本分类;垃圾邮件过滤;情感分析,朴素贝叶斯分类器是一种基于贝叶斯定理和特征条件独立性假设的概率分类器。它假设给定类别的情况下，特征之间是相互独立的（“朴素”假设）。通过计算每个类别下每个特征的条件概率，然后利用贝叶斯公式计算后验概率，选择后验概率最大的类别作为预测结果。,人工智能;机器学习;自然语言处理,优点：算法简单，易于实现。训练速度快，在处理大规模文本数据时表现良好。在数据量较少的情况下也能有不错的表现。缺点：“朴素”假设在现实世界中往往不成立，可能导致分类精度下降。对输入数据的形式敏感。
A057,主成分分析,Principal Component Analysis (PCA),机器学习,降维;特征提取,O(min(N，D)^2 * max(N，D)),O(D^2),不适用,数据可视化;特征降维;噪声去除,主成分分析是一种常用的数据降维技术。它通过正交变换将原始数据变换到一个新的坐标系中，使得数据在第一个坐标轴（主成分）上的方差最大，第二个坐标轴上的方差次之，以此类推。目标是找到数据中最重要的“主成分”，从而减少数据的维度，同时保留大部分信息。,人工智能;机器学习;数据分析;图像处理,优点：能够有效降低数据维度，减少计算量，去除噪声。提高模型训练效率，避免维度灾难。缺点：主成分的可解释性可能较差。是线性降维方法，对于非线性结构的数据效果不佳。
A058,梯度下降,Gradient Descent,优化算法,数值优化,O(迭代次数 * 样本数 * 特征数),O(特征数),不适用,机器学习模型训练;神经网络训练,梯度下降是一种常用的优化算法，用于最小化（或最大化）一个函数。它通过沿着函数梯度（或负梯度）的方向迭代地调整参数，逐步逼近函数的局部最小值（或最大值）。有批量梯度下降、随机梯度下降、小批量梯度下降等变种。,人工智能;机器学习;深度学习,优点：简单，易于实现。是许多机器学习模型（如线性回归、逻辑回归、神经网络）训练的核心算法。缺点：可能收敛到局部最优，而不是全局最优。学习率的选择很重要，过大可能导致震荡，过小可能收敛慢。对特征缩放敏感。
A077,R-CNN系列,Region-based Convolutional Neural Network (R-CNN),机器学习,深度学习;目标检测,训练O(迭代次数 * 样本数 * 区域建议数)，预测O(区域建议数 * 分类器复杂度),O(网络参数量),不适用,目标检测;图像识别,R-CNN系列（包括R-CNN，Fast R-CNN，Faster R-CNN）是早期的经典目标检测算法。它们通常分为两个阶段：第一阶段生成区域建议（Region Proposals），第二阶段对这些区域进行分类和边界框回归。Faster R-CNN引入了区域建议网络（RPN）来生成区域建议，大大提高了速度。,人工智能;机器学习;计算机视觉;图像识别,优点：检测精度高，尤其是在早期版本中。缺点：R-CNN速度慢，Fast R-CNN解决了部分问题，Faster R-CNN在速度和精度上取得了很好的平衡，但仍不如YOLO等单阶段检测器快。
A087,元学习,Meta-Learning (Learning to Learn),机器学习,学习范式,多变,多变,不适用,小样本学习;快速适应新任务,元学习是一种“学习如何学习”的机器学习范式。它旨在训练模型，使其能够快速适应新任务或新环境，即使只有少量训练样本。通过在多个相关任务上进行训练，模型学习到一种通用的学习策略或初始化参数，使其在新任务上能够快速收敛。,人工智能;机器学习;深度学习;小样本学习,优点：在小样本学习、零样本学习等场景下表现出色，能够快速适应新任务。提高了模型的泛化能力。缺点：算法复杂，训练困难。计算资源消耗大。
A088,决策树剪枝,Decision Tree Pruning,机器学习,决策树优化,O(树的节点数),O(树的节点数),不适用,决策树过拟合控制,决策树剪枝是用于防止决策树过拟合的技术。主要分为预剪枝（在树生长过程中限制其复杂度）和后剪枝（先生成完整树，再从叶子节点向上剪掉不必要的子树）。通过评估剪枝对泛化性能的影响来决定是否剪枝。,人工智能;机器学习;数据挖掘,优点：有效控制决策树的复杂度，提高模型的泛化能力，避免过拟合。缺点：预剪枝可能导致欠拟合。后剪枝计算成本较高。
A093,Isolation Forest,Isolation Forest,机器学习,异常检测,O(树的数量 * 样本数 * log 样本数),O(树的数量 * 树的深度),不适用,网络入侵检测;金融欺诈检测;工业故障诊断,Isolation Forest是一种基于集成学习的异常检测算法。它通过随机选择特征和随机选择分割点来构建多棵孤立树（Isolation Tree）。异常点通常是少数且与正常点差异大，因此在孤立树中更容易被孤立（即路径长度更短）。通过计算平均路径长度来评估异常分数。,人工智能;机器学习;异常检测;数据挖掘,优点：对高维数据和大规模数据集有较好的处理能力。无需距离或密度计算，效率高。对异常值敏感。缺点：对异常点的定义敏感，可能将正常但稀疏的点误判为异常。不适用于所有类型的数据分布。

A098,PageRank算法,PageRank Algorithm,图算法,链接分析,O(迭代次数 * 边数),O(节点数),不适用,网页排名;社交网络影响力分析;学术引用分析,PageRank算法是Google搜索引擎的核心算法之一，用于评估网页的重要性。它基于“一个网页的重要性取决于指向它的其他网页的重要性”这一思想。算法通过迭代计算每个网页的PageRank值，直到收敛。它模拟了用户随机漫步的行为。,计算机科学;图论;信息检索;网络科学,优点：能够客观评估网页或节点的重要性。在搜索引擎、推荐系统等领域有广泛应用。缺点：算法收敛速度可能较慢。容易受到链接作弊的影响。不考虑链接的语义信息。
A099,HITS算法,HITS Algorithm,图算法,链接分析,O(迭代次数 * 边数),O(节点数),不适用,网页排名;社交网络影响力分析,HITS（Hyperlink-Induced Topic Search）算法用于评估网页的权威性（Authority）和中心性（Hub）。权威页面是包含有用信息的页面，中心页面是指向许多权威页面的页面。算法通过迭代计算每个网页的Authority值和Hub值，直到收敛。与PageRank不同，HITS是基于查询的。,计算机科学;图论;信息检索;网络科学,优点：能够区分网页的权威性和中心性，提供更丰富的评价信息。缺点：计算成本相对较高。容易受到链接作弊的影响。
A100,EM算法,Expectation-Maximization (EM) Algorithm,机器学习,概率模型参数估计,O(迭代次数 * 样本数 * 特征数),O(模型参数量),不适用,混合高斯模型;隐马尔可夫模型;聚类,EM算法是一种迭代算法，用于在存在隐变量的概率模型中估计参数。它包括两个步骤：E步（期望步）和M步（最大化步）。E步：根据当前参数估计隐变量的后验概率。M步：根据E步计算出的隐变量后验概率，最大化完全数据的似然函数，更新模型参数。重复E步和M步直到收敛。,人工智能;机器学习;统计学;模式识别,优点：能够处理含有隐变量的模型参数估计问题。在许多无监督学习任务中应用广泛。缺点：可能收敛到局部最优，而不是全局最优。收敛速度可能较慢。对初始参数敏感。
A101,隐马尔可夫模型,Hidden Markov Model (HMM),机器学习,序列模型,O(序列长度 * 状态数^2),O(状态数^2),不适用,语音识别;自然语言处理;生物信息学,HMM是一种统计模型，用于描述一个含有隐变量的随机过程。它假设系统状态是不可见的（隐变量），但可以通过一系列可观察的输出序列来推断。HMM包含初始状态概率、状态转移概率和观测概率。主要问题包括评估（前向/后向算法）、解码（Viterbi算法）和学习（Baum-Welch算法）。,人工智能;机器学习;自然语言处理;语音识别;生物信息学,优点：能够对序列数据进行建模，处理时间依赖关系。在语音识别、自然语言处理等领域有广泛应用。缺点：独立性假设有时过于严格。计算复杂度高，尤其是在状态数和序列长度较大时。
A102,维特比算法,Viterbi Algorithm,动态规划,序列解码,O(序列长度 * 状态数^2),O(序列长度 * 状态数),不适用,隐马尔可夫模型解码;语音识别;自然语言处理,维特比算法是一种动态规划算法，用于在隐马尔可夫模型（HMM）中找到给定观测序列下最可能的状态序列。它通过构建一个格（Lattice）图，并利用动态规划的思想，在每一步计算到达每个状态的最大概率路径，从而高效地找到全局最优路径。,计算机科学;动态规划;语音识别;自然语言处理,优点：能够高效地找到HMM中最优的状态序列。在语音识别、自然语言处理等领域有核心应用。缺点：计算复杂度与状态数平方成正比，当状态数非常大时效率降低。
A103,前向-后向算法,Forward-Backward Algorithm,动态规划,概率计算,O(序列长度 * 状态数^2),O(序列长度 * 状态数),不适用,隐马尔可夫模型评估;参数估计,前向-后向算法是隐马尔可夫模型（HMM）中的一种动态规划算法，用于计算给定观测序列的概率（评估问题），以及计算隐状态的后验概率。它由前向算法和后向算法两部分组成，分别从前往后和从后往前计算概率。,计算机科学;动态规划;语音识别;自然语言处理,优点：能够高效地计算HMM的观测序列概率，是HMM参数学习（Baum-Welch算法）的基础。缺点：计算复杂度与状态数平方成正比。
A106,马尔可夫链蒙特卡罗,Markov Chain Monte Carlo (MCMC),统计学,采样方法,多变,多变,不适用,贝叶斯推断;复杂概率分布采样;统计物理模拟,MCMC是一类用于从复杂概率分布中采样的算法。它通过构建一个马尔可夫链，使其平稳分布是目标分布，然后从该马尔可夫链中进行采样。常见的MCMC算法包括Metropolis-Hastings算法和Gibbs采样。,统计学;机器学习;贝叶斯推断;物理学,优点：能够从高维、复杂的概率分布中进行采样，尤其适用于贝叶斯推断。缺点：收敛速度可能较慢，需要大量的样本。需要判断马尔可夫链是否收敛。
A107,Metropolis-Hastings算法,Metropolis-Hastings Algorithm,统计学,采样方法,多变,多变,不适用,贝叶斯推断;复杂概率分布采样,Metropolis-Hastings算法是一种MCMC方法，用于从难以直接采样的概率分布中生成样本。它通过一个提议分布（Proposal Distribution）生成候选样本，然后根据接受概率决定是否接受该样本。接受概率的设计确保了马尔可夫链的平稳分布是目标分布。,统计学;机器学习;贝叶斯推断,优点：能够从各种复杂分布中采样，无需知道归一化常数。缺点：需要选择合适的提议分布。收敛速度可能较慢。
A108,Gibbs采样,Gibbs Sampling,统计学,采样方法,多变,多变,不适用,贝叶斯推断;图像去噪;主题模型,Gibbs采样是MCMC方法的一种特例，适用于多维联合分布的采样。它通过依次从每个变量以其他所有变量为条件的条件分布中进行采样，从而生成联合分布的样本。当条件分布易于采样时，Gibbs采样非常高效。,统计学;机器学习;贝叶斯推断;图像处理,优点：当条件分布易于采样时，实现简单且高效。在许多统计模型中应用广泛。缺点：需要知道所有变量的条件分布。如果变量之间高度相关，收敛速度可能较慢。
A109,Latent Dirichlet Allocation (LDA),LDA,机器学习,主题模型,O(迭代次数 * 词汇量 * 主题数),O(词汇量 * 主题数),不适用,文本主题发现;文档分类;信息检索,LDA是一种生成式概率模型，用于发现文档集合中的抽象“主题”。它假设每篇文档都是由多个主题混合而成，每个主题又由多个词语组成。通过推断文档-主题分布和主题-词语分布，从而发现隐藏的主题结构。通常使用Gibbs采样或变分推断进行参数估计。,人工智能;机器学习;自然语言处理;信息检索,优点：能够从大量文本中自动发现主题，具有良好的可解释性。在文档分类、推荐系统等领域有广泛应用。缺点：需要预先指定主题数量。对短文本效果不佳。
A110,Singular Value Decomposition (SVD),SVD,线性代数,矩阵分解;降维,O(min(m，n)^2 * max(m，n)),O(mn),不适用,推荐系统;图像压缩;降维;文本语义分析,SVD是一种重要的矩阵分解方法，它将任意矩阵分解为三个矩阵的乘积：一个正交矩阵U，一个对角矩阵Sigma（包含奇异值），和一个正交矩阵V的转置。奇异值分解可以用于降维、去噪、推荐系统等。,计算机科学;线性代数;机器学习;数据分析,优点：具有广泛的应用，能够揭示数据中的潜在结构。是许多数据分析和机器学习算法的基础。缺点：计算成本高，不适用于非常大的矩阵。结果的可解释性可能不如PCA直观。
A111,协同过滤,Collaborative Filtering,机器学习,推荐系统,O(用户数 * 物品数) 或 O(用户数^2) 或 O(物品数^2),O(用户数 * 物品数),不适用,商品推荐;电影推荐;音乐推荐,协同过滤是一种常用的推荐算法。它基于“物以类聚，人以群分”的思想，通过分析用户或物品之间的相似性来生成推荐。主要分为基于用户的协同过滤（User-Based CF）和基于物品的协同过滤（Item-Based CF）。,人工智能;机器学习;推荐系统;电子商务,优点：无需对物品或用户进行领域知识建模。能够发现用户潜在的兴趣。缺点：冷启动问题（新用户或新物品没有足够的交互数据）。数据稀疏性问题。可扩展性差，计算成本高。
A112,矩阵分解,Matrix Factorization,机器学习,推荐系统;降维,O(迭代次数 * 因子数 * 用户数 * 物品数),O(因子数 * (用户数 + 物品数)),不适用,推荐系统;隐语义模型,矩阵分解是一种将高维稀疏矩阵（如用户-物品评分矩阵）分解为两个或多个低维稠密矩阵的方法。这些低维矩阵的乘积可以近似原始矩阵。在推荐系统中，分解后的矩阵可以表示用户和物品的隐因子（Latent Factors），通过这些因子可以预测用户对未评分物品的偏好。,人工智能;机器学习;推荐系统;数据降维,优点：能够有效解决协同过滤中的数据稀疏性和可扩展性问题。能够发现用户和物品的潜在特征。缺点：模型可解释性相对较差。对冷启动问题效果不佳。
A113,傅里叶变换,Fourier Transform,信号处理,变换,O(N log N),O(N),不适用,信号分析;图像处理;数据压缩;频谱分析,傅里叶变换是一种将信号从时域（或空域）转换到频域的数学方法。它将一个函数分解成不同频率的正弦和余弦函数的叠加。快速傅里叶变换（FFT）是其高效的实现算法。核心思想是任何周期信号都可以表示为一系列正弦波的叠加。,计算机科学;信号处理;图像处理;物理学,优点：能够揭示信号的频率成分，用于频谱分析、滤波、压缩等。FFT使其计算效率高。缺点：仅适用于平稳信号，对于非平稳信号（如瞬时频率变化）效果不佳。
A114,快速傅里叶变换,Fast Fourier Transform (FFT),信号处理,变换,O(N log N),O(N),不适用,信号分析;图像处理;数据压缩;频谱分析,FFT是离散傅里叶变换（DFT）的一种高效算法，将DFT的计算复杂度从O(N^2)降低到O(N log N)。它利用了DFT计算中的对称性和周期性，将一个N点DFT分解为两个N/2点DFT，然后递归地进行。是数字信号处理领域的基石。,计算机科学;信号处理;图像处理;物理学,优点：计算效率极高，使得傅里叶变换在实际应用中成为可能。广泛应用于信号处理、图像处理、数据压缩等领域。缺点：要求数据点数量是2的幂次方（对于某些FFT算法）。
A115,小波变换,Wavelet Transform,信号处理,变换,O(N),O(N),不适用,信号分析;图像压缩;去噪;特征提取,小波变换是一种在时域和频域同时具有局部化能力的信号分析方法。与傅里叶变换将信号分解为无限长的正弦波不同，小波变换使用有限长、快速衰减的“小波”函数来分析信号。它能够捕捉信号的瞬时特征和局部细节。,计算机科学;信号处理;图像处理;数据压缩,优点：具有多分辨率分析能力，能够同时分析信号的时域和频域信息。适用于非平稳信号的分析。在图像压缩、去噪、特征提取等领域表现出色。缺点：小波基函数的选择对性能有影响。计算量相对较大。
A116,动态时间规整,Dynamic Time Warping (DTW),序列比对,相似度度量,O(mn),O(mn),不适用,语音识别;手势识别;时间序列比对,DTW是一种用于衡量两个时间序列之间相似度的方法，即使它们在时间轴上存在非线性扭曲或速度变化。它通过找到一个最优的“弯曲路径”，使得两个序列在时间上对齐，并最小化对齐后的距离。常用于语音识别中不同语速下的词语匹配。,计算机科学;信号处理;语音识别;模式识别,优点：能够处理时间序列的非线性扭曲，比欧氏距离更准确地衡量相似度。缺点：计算成本高，时间复杂度为O(mn)，不适用于非常长的时间序列。对异常值敏感。
A117,欧几里得算法,Euclidean Algorithm,数学,数论,O(log(min(a，b))),O(1),不适用,最大公约数计算;密码学,欧几里得算法（又称辗转相除法）用于计算两个正整数的最大公约数（GCD）。其核心思想是两个正整数a和b（a > b）的最大公约数等于b和a除以b的余数的最大公约数。通过递归或迭代地进行此操作，直到余数为0，此时的除数即为最大公约数。,计算机科学;数学;密码学,优点：算法简单，高效，是计算最大公约数的标准方法。缺点：仅适用于正整数。
A118,扩展欧几里得算法,Extended Euclidean Algorithm,数学,数论,O(log(min(a，b))),O(1),不适用,模逆元计算;线性同余方程求解;密码学,扩展欧几里得算法在计算两个整数a和b的最大公约数GCD(a，b)的同时，还能找到一对整数x和y，使得$ax + by = GCD(a，b)$。它是求解模逆元和线性同余方程的基础。,计算机科学;数学;密码学,优点：能够求解模逆元和线性同余方程，在密码学中（如RSA算法）有重要应用。缺点：理解和实现相对复杂。
A119,中国剩余定理,Chinese Remainder Theorem (CRT),数学,数论,O(k * log(N)),O(k),不适用,大整数计算;密码学;同余方程组求解,中国剩余定理用于解决一组同余方程组。它提供了一种方法，可以从多个模数下的大整数的余数，重构出这个大整数。前提是所有模数两两互质。,计算机科学;数学;密码学,优点：能够将大整数的计算分解为多个小整数的计算，从而简化问题。在密码学、编码理论等领域有重要应用。缺点：要求模数两两互质。
A120,素性测试,Primality Test,数学,数论,多变,多变,不适用,大素数生成;密码学,素性测试是判断一个给定正整数是否为素数（质数）的算法。常见的有试除法、费马素性测试、米勒-拉宾素性测试等。在密码学中，需要生成大素数作为密钥。,计算机科学;数学;密码学,优点：能够判断一个数是否为素数，是密码学的基础。缺点：对于大数，确定性素性测试算法效率较低。概率性素性测试（如米勒-拉宾）有误判的概率（尽管很小）。
A121,Miller-Rabin素性测试,Miller-Rabin Primality Test,数学,数论,O(k * log^3 n),O(log n),不适用,大素数测试;密码学,Miller-Rabin算法是一种概率性素性测试算法，用于判断一个大整数是否为素数。它基于费马小定理和二次探测定理，通过随机选择基数进行多次测试。如果通过所有测试，则该数很可能是素数；如果未通过任何测试，则它一定是合数。,计算机科学;数学;密码学,优点：对于大整数，效率远高于确定性素性测试。在实际应用中，通过少量迭代即可达到非常高的准确率。缺点：是概率性算法，存在极小的误判概率（将合数判断为素数）。
A122,RSA算法,RSA Algorithm,密码学,公钥加密,加密/解密O(log^3 N)，密钥生成O(log^4 N),O(log N),不适用,数据加密;数字签名;密钥交换,RSA是一种非对称加密算法，也是第一个能用于数据加密和数字签名的算法。它基于大整数分解的困难性。包含密钥生成（选择两个大素数）、加密（使用公钥）和解密（使用私钥）三个过程。,计算机科学;密码学;网络安全,优点：安全性高，广泛应用于数据加密和数字签名。是现代密码学的基础之一。缺点：计算速度相对较慢，不适合加密大量数据。密钥长度需要足够大以保证安全性。
A123,AES算法,Advanced Encryption Standard (AES),密码学,对称加密,O(数据块大小 * 轮数),O(密钥长度),不适用,数据加密;文件加密;网络通信加密,AES是一种对称密钥加密算法，是目前最常用的加密算法之一。它使用相同的密钥进行加密和解密。AES支持128、192和256位的密钥长度，采用分组密码模式，将明文分成固定大小的块进行加密。,计算机科学;密码学;网络安全,优点：加密速度快，效率高，安全性强。被广泛应用于各种加密场景。缺点：需要安全地分发密钥，密钥管理是挑战。
A124,MD5,Message-Digest Algorithm 5 (MD5),密码学,哈希函数,O(消息长度),O(1),不适用,数据完整性校验;文件校验;密码存储(不推荐),MD5是一种广泛使用的密码散列函数，可以生成一个128位的哈希值（或消息摘要）。它将任意长度的输入数据映射为固定长度的输出。虽然曾用于数据完整性校验，但由于存在碰撞攻击，已不推荐用于安全性要求高的场景。,计算机科学;密码学;数据完整性,优点：计算速度快，生成固定长度的哈希值。缺点：存在碰撞攻击（不同输入可能产生相同哈希值），不适合用于数字签名或密码存储（应使用更安全的哈希算法）。
A125,SHA-256,Secure Hash Algorithm 256 (SHA-256),密码学,哈希函数,O(消息长度),O(1),不适用,数据完整性校验;数字签名;区块链;密码存储,SHA-256是SHA-2家族中的一种密码散列函数，可以生成一个256位的哈希值。它比MD5更安全，广泛应用于数字签名、SSL/TLS、区块链等领域。,计算机科学;密码学;网络安全;区块链,优点：安全性高，目前尚未发现有效的碰撞攻击。广泛应用于各种安全场景。缺点：计算速度相对较慢。
A126,DH密钥交换,Diffie-Hellman Key Exchange,密码学,密钥交换,O(log^3 N),O(log N),不适用,安全通信;密钥协商,Diffie-Hellman密钥交换是一种在不安全的信道上安全地交换加密密钥的方法。它允许通信双方在不共享任何秘密信息的情况下，协商出一个共享的秘密密钥。基于离散对数问题的困难性。,计算机科学;密码学;网络安全,优点：能够在不安全的信道上建立共享密钥，是许多安全协议（如SSL/TLS）的基础。缺点：容易受到中间人攻击，需要额外的认证机制来防止。
A127,椭圆曲线密码学,Elliptic Curve Cryptography (ECC),密码学,公钥加密,加密/解密O(曲线参数)，密钥生成O(曲线参数),O(曲线参数),不适用,数据加密;数字签名;密钥交换,ECC是一种基于椭圆曲线数学的公钥密码学方法。与RSA相比，ECC在相同安全强度下所需的密钥长度更短，因此计算效率更高，更适合资源受限的环境（如移动设备）。,计算机科学;密码学;网络安全,优点：在相同安全级别下，密钥长度比RSA短得多，因此计算速度更快，存储空间更小。适用于资源受限的设备。缺点：数学理论复杂，实现难度高。
A128,数字签名算法,Digital Signature Algorithm (DSA),密码学,数字签名,签名O(log^3 N)，验证O(log^3 N),O(log N),不适用,数据完整性;身份认证;不可否认性,DSA是一种用于生成和验证数字签名的算法。它允许消息的发送者对其消息进行签名，以证明消息的来源和完整性，并提供不可否认性。基于离散对数问题的困难性。,计算机科学;密码学;网络安全,优点：能够提供数据完整性、身份认证和不可否认性。缺点：仅用于数字签名，不能用于数据加密。
A129,哈希表,Hash Table,数据结构,查找;存储,平均O(1)，最坏O(n),O(n),不适用,快速查找;缓存;数据库索引;符号表,哈希表（或散列表）是一种通过哈希函数将键映射到数组索引来存储和检索数据的数据结构。它提供了平均O(1)的查找、插入和删除操作。通过处理哈希冲突（如链地址法、开放寻址法）来应对多个键映射到同一索引的情况。,计算机科学;数据结构;数据库;操作系统,优点：平均查找、插入和删除操作时间复杂度为O(1)，效率极高。缺点：最坏情况下可能退化到O(n)（所有元素哈希到同一位置）。需要选择合适的哈希函数和冲突解决策略。哈希表的大小对性能有影响。
A130,二叉搜索树,Binary Search Tree (BST),数据结构,查找;存储,平均O(log n)，最坏O(n),平均O(log n)，最坏O(n),不适用,动态数据查找;排序;字典实现,二叉搜索树是一种特殊的二叉树，其中每个节点的左子树只包含小于当前节点的值，右子树只包含大于当前节点的值。这使得查找、插入和删除操作的平均时间复杂度为O(log n)。,计算机科学;数据结构;数据库,优点：支持高效的查找、插入和删除操作。可以进行范围查询。缺点：在最坏情况下（如插入有序序列），树可能退化为链表，导致操作时间复杂度变为O(n)。需要平衡化（如AVL树、红黑树）来保证性能。
A131,AVL树,AVL Tree,数据结构,查找;存储,O(log n),O(log n),不适用,动态数据查找;数据库索引,AVL树是一种自平衡二叉搜索树。它通过在每次插入或删除操作后检查并调整节点的平衡因子（左右子树高度差的绝对值不超过1），确保树的高度差不超过1，从而保证树的高度始终为O(log n)，进而保证所有操作的时间复杂度为O(log n)。,计算机科学;数据结构;数据库,优点：所有操作（查找、插入、删除）的时间复杂度均为O(log n)，性能稳定。缺点：实现相对复杂，需要进行旋转操作来维护平衡。
A132,红黑树,Red-Black Tree,数据结构,查找;存储,O(log n),O(log n),不适用,动态数据查找;Map/Set实现;Linux内核调度,红黑树是一种自平衡二叉搜索树，它通过为每个节点着色（红色或黑色）并遵循一系列规则来保持树的平衡。它不追求严格的平衡，而是保证从根到叶子的最长路径不超过最短路径的两倍，从而保证操作的对数时间复杂度。,计算机科学;数据结构;操作系统;数据库,优点：所有操作（查找、插入、删除）的时间复杂度均为O(log n)，性能稳定。实现相对AVL树更宽松，旋转次数通常更少。广泛应用于标准库和操作系统内核。缺点：实现比普通二叉搜索树复杂。
A133,B树,B-Tree,数据结构,查找;存储,O(log N),O(N),不适用,数据库索引;文件系统,B树是一种多路平衡查找树，广泛应用于数据库和文件系统。它允许一个节点包含多个子节点，并且所有叶子节点都位于同一层。B树的特点是节点中的键值和子节点指针数量可以动态变化，以适应磁盘IO的特性，减少磁盘访问次数。,计算机科学;数据结构;数据库;文件系统,优点：非常适合磁盘等外部存储，能够显著减少磁盘IO次数，提高查询效率。所有操作的时间复杂度均为O(log N)。缺点：实现比二叉树复杂。
A134,B+树,B+ Tree,数据结构,查找;存储,O(log N),O(N),不适用,数据库索引;文件系统,B+树是B树的一种变体，在数据库和文件系统中更为常用。它的主要特点是所有数据都存储在叶子节点中，并且叶子节点之间通过链表连接。非叶子节点只存储键值和子节点指针，用于索引。这使得范围查询更加高效。,计算机科学;数据结构;数据库;文件系统,优点：所有数据都在叶子节点，有利于范围查询和全表扫描。磁盘IO效率高。缺点：实现比B树更复杂。
A135,Trie树,Trie (Prefix Tree),数据结构,查找;存储,O(L) (L为字符串长度),O(N*L) (N为字符串数量),不适用,字符串查找;前缀匹配;自动补全;拼写检查,Trie树（或前缀树、字典树）是一种用于高效存储和检索字符串集合的树形数据结构。每个节点代表一个字符，从根到某个节点的路径表示一个字符串。它通过共享前缀来节省空间，并支持快速的前缀查找。,计算机科学;数据结构;字符串处理;搜索引擎,优点：支持高效的前缀查找和匹配。空间效率高（当有大量共同前缀时）。缺点：如果字符串集合中没有太多共同前缀，空间效率可能不高。
A136,并查集,Disjoint Set Union (DSU),数据结构,集合操作,平均O(α(n)),O(n),不适用,连通分量;最小生成树(Kruskal);网络连通性,并查集是一种用于管理元素分组的数据结构，支持两种主要操作：查找（Find），确定元素所属的集合；合并（Union），将两个集合合并为一个。通过路径压缩和按秩合并（或按大小合并）等优化，操作的平均时间复杂度接近常数。,计算机科学;数据结构;图论;算法竞赛,优点：能够高效地进行集合的合并与查找操作。实现相对简单。缺点：无法支持删除操作。
A137,线段树,Segment Tree,数据结构,区间查询;区间修改,O(log n),O(n),不适用,区间求和;区间最值;区间更新,线段树是一种二叉树数据结构，用于高效地处理区间（或线段）上的查询和修改操作。每个节点代表一个区间，叶子节点代表最小的单元区间。非叶子节点存储其子节点区间的聚合信息。支持单点更新和区间更新，以及区间查询。,计算机科学;数据结构;算法竞赛,优点：能够高效地处理各种区间查询和修改操作，时间复杂度为O(log n)。缺点：实现相对复杂。空间复杂度为O(n)。
A138,树状数组,Fenwick Tree (BIT),数据结构,前缀和;单点修改,O(log n),O(n),不适用,前缀和查询;单点更新;逆序对计数,树状数组（或二叉索引树）是一种数据结构，用于高效地计算数组的前缀和以及进行单点更新。它利用二进制表示来快速定位需要更新或查询的区间。与线段树相比，实现更简单，常数因子更小。,计算机科学;数据结构;算法竞赛,优点：实现简单，常数因子小，效率高。支持单点更新和前缀和查询，时间复杂度均为O(log n)。缺点：功能不如线段树强大，只能处理前缀和相关的问题。
A139,跳表,Skip List,数据结构,查找;存储,平均O(log n)，最坏O(n),平均O(n)，最坏O(n),不适用,动态数据查找;数据库索引;缓存,跳表是一种基于并行链表的概率性数据结构，用于实现有序集合或映射。它通过在多层链表中随机跳跃来加速查找操作。每一层链表都是下一层链表的子序列，且元素有序。通过随机决定每个元素在多少层中出现，从而实现对数级的查找效率。,计算机科学;数据结构;数据库;缓存,优点：实现比平衡二叉搜索树简单。平均查找、插入和删除操作时间复杂度为O(log n)。支持范围查询。缺点：最坏情况下可能退化到O(n)。空间复杂度相对较高。
A140,布隆过滤器,Bloom Filter,数据结构,集合成员测试,O(k),O(m),不适用,快速判断元素是否存在;缓存穿透;垃圾邮件过滤,布隆过滤器是一种空间效率高、但有一定误判率的概率型数据结构，用于判断一个元素是否在一个集合中。它通过多个哈希函数将元素映射到位数组中的多个位置，并将这些位置置为1。查询时，如果所有对应的位置都为1，则元素可能存在；如果有任何一个位置为0，则元素一定不存在。存在误判，但不会漏判。,计算机科学;数据结构;大数据;缓存,优点：空间效率极高，比哈希表节省大量空间。查询速度快。缺点：存在误判率（将不存在的元素判断为存在）。不支持删除操作。
A141,LRU缓存淘汰算法,Least Recently Used (LRU),缓存算法,缓存管理,O(1),O(容量),不适用,缓存管理;内存管理,LRU算法是一种常用的缓存淘汰策略。当缓存空间不足时，它会淘汰最近最少使用的数据。通常使用双向链表和哈希表的组合来实现：哈希表用于快速查找，双向链表用于维护访问顺序，最近访问的元素移到链表头部，最久未使用的元素在链表尾部。,计算机科学;操作系统;数据库;网络,优点：能够有效利用缓存空间，提高缓存命中率。缺点：需要维护访问顺序，实现相对复杂。无法处理未来访问模式。
A142,LFI缓存淘汰算法,Least Frequently Used (LFU),缓存算法,缓存管理,O(log N) 或 O(1),O(容量),不适用,缓存管理;内存管理,LFU算法是一种缓存淘汰策略，当缓存空间不足时，它会淘汰访问频率最低的数据。通常使用哈希表和最小堆（或频率链表）来实现：哈希表用于快速查找，最小堆用于维护访问频率，频率最低的元素在堆顶。,计算机科学;操作系统;数据库;网络,优点：能够淘汰真正不常用的数据，可能比LRU更有效。缺点：实现比LRU复杂。无法处理访问频率随时间变化的情况（如某个数据在短时间内访问频繁，但之后不再访问）。
A143,Aho-Corasick算法,Aho-Corasick Algorithm,字符串,多模式匹配,O(N+M+K) (K为匹配次数),O(M),不适用,多模式匹配;敏感词过滤;病毒扫描,Aho-Corasick算法是一种用于在文本中查找多个模式串的高效算法。它通过构建一个有限状态自动机（Trie树结合失败指针）来同时匹配所有模式串。当文本扫描到一个字符时，自动机根据当前状态和输入字符进行状态转移，并报告匹配到的模式串。,计算机科学;字符串处理;信息安全,优点：能够在线性时间内同时查找多个模式串，效率高。广泛应用于敏感词过滤、病毒扫描等。缺点：算法实现相对复杂。
A144,后缀数组,Suffix Array,字符串,字符串分析,O(N log N),O(N),不适用,字符串匹配;最长公共前缀;基因组分析,后缀数组是一个字符串所有后缀经过排序后得到的起始位置的数组。它是一种重要的字符串数据结构，可以用于解决许多字符串问题，如字符串匹配、最长公共前缀（LCP）数组的构建、重复子串查找等。,计算机科学;字符串处理;生物信息学,优点：能够高效地解决多种字符串问题。缺点：构建算法相对复杂。
A145,后缀树,Suffix Tree,字符串,字符串分析,O(N),O(N),不适用,字符串匹配;最长公共子串;基因组分析,后缀树是一个字符串所有后缀的压缩Trie树。它是一种非常强大的字符串数据结构，可以在线性时间内构建，并用于解决各种复杂的字符串问题，如最长重复子串、最长公共子串、最短唯一子串等。,计算机科学;字符串处理;生物信息学,优点：能够在线性时间内解决许多复杂的字符串问题。缺点：构建算法非常复杂，实现难度大。空间消耗相对较大。
A146,Z-Algorithm (字符串),Z-Algorithm,字符串,模式匹配,O(N+M),O(N+M),不适用,字符串匹配;模式匹配;LCP数组构建,Z算法（也称为Z-box算法）用于计算一个字符串S的Z数组。Z数组$Z[i]$表示S和S的后缀$S[i..]$的最长公共前缀的长度。通过计算Z数组，可以高效地进行字符串匹配。核心思想是利用已经计算的Z值，避免重复比较，实现线性时间复杂度。,计算机科学;字符串处理;文本分析,优点：时间复杂度为O(N+M)，是线性时间算法，非常高效。可以用于解决字符串匹配问题，比KMP更易于理解和实现。缺点：相对KMP，其应用场景可能更专注于LCP（最长公共前缀）的计算，但同样可以解决模式匹配。
A147,高斯消元法,Gaussian Elimination,线性代数,方程求解,O(n^3),O(n^2),不适用,线性方程组求解;矩阵求逆;行列式计算,高斯消元法是一种用于求解线性方程组的算法。它通过一系列行变换（交换两行、某行乘以非零常数、某行加上另一行的倍数）将增广矩阵化为行阶梯形或简化行阶梯形，从而得到方程组的解。也可用于计算矩阵的逆和行列式。,计算机科学;数学;数值计算,优点：能够求解任意线性方程组。算法思想直观，易于理解。缺点：时间复杂度为O(n^3)，对于大规模方程组效率较低。对浮点数计算可能存在精度问题。
A148,LU分解,LU Decomposition,线性代数,矩阵分解,O(n^3),O(n^2),不适用,线性方程组求解;矩阵求逆;行列式计算,LU分解将一个方阵A分解为一个下三角矩阵L和一个上三角矩阵U的乘积，即$A = LU$。通过LU分解，可以更高效地求解多个具有相同系数矩阵的线性方程组，以及计算矩阵的逆和行列式。,计算机科学;数学;数值计算,优点：一旦完成分解，求解线性方程组、计算逆矩阵等操作会更快。缺点：计算成本高，时间复杂度为O(n^3)。并非所有矩阵都存在LU分解，需要进行行交换（PLU分解）。
A149,QR分解,QR Decomposition,线性代数,矩阵分解,O(mn^2),O(mn),不适用,最小二乘问题;特征值计算,QR分解将一个矩阵A分解为一个正交矩阵Q和一个上三角矩阵R的乘积，即$A = QR$。它常用于求解线性最小二乘问题和计算矩阵的特征值。常用的方法有Householder变换和Givens旋转。,计算机科学;数学;数值计算,优点：在数值稳定性方面优于LU分解。广泛应用于最小二乘问题和特征值计算。缺点：计算成本高。
A154,DBSCAN聚类,DBSCAN Clustering,机器学习,聚类,O(N log N) 或 O(N^2),O(N),不适用,空间数据聚类;异常检测;发现任意形状簇,DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一种基于密度的聚类算法。它将紧密连接在一起的数据点分组为簇，并标记出离群点。它不需要预先指定簇的数量，能够发现任意形状的簇，并且对噪声具有鲁棒性。,人工智能;机器学习;数据挖掘;地理信息系统,优点：能够发现任意形状的簇。不需要预先指定簇的数量。对噪声具有鲁棒性。缺点：对参数（Epsilon和MinPts）的选择敏感。对于密度不均匀的数据集效果不佳。
A155,高斯混合模型,Gaussian Mixture Model (GMM),机器学习,聚类;密度估计,O(迭代次数 * 样本数 * 维度 * 簇数),O(簇数 * 维度^2),不适用,聚类;密度估计;语音识别,GMM是一种概率模型，假设数据是由多个高斯分布（正态分布）混合生成的。它通过EM算法来估计每个高斯分布的参数（均值、协方差、权重），从而将数据点分配到最可能属于的簇。可以用于聚类和密度估计。,人工智能;机器学习;模式识别;语音识别,优点：能够发现非球形簇。可以给出数据点属于每个簇的概率。缺点：需要预先指定簇的数量。对初始参数敏感，可能收敛到局部最优。计算成本相对较高。
A156,决策树回归,Decision Tree Regression,机器学习,回归,O(特征数 * 样本数 * log 样本数),O(树的深度),不适用,连续值预测;房价预测,决策树回归是决策树在回归任务上的应用。它通过递归地将数据集划分为更小的子区域，每个子区域的预测值是该区域内所有样本的平均值（或其他统计量）。与分类树类似，通过最小化平方误差来选择最佳分裂点。,人工智能;机器学习;数据挖掘,优点：模型易于理解和解释。可以处理数值型和类别型数据。缺点：容易过拟合。对数据中的噪声敏感。决策边界是轴平行的。
A157,支持向量回归,Support Vector Regression (SVR),机器学习,回归,训练O(n^2)到O(n^3)，预测O(维度),O(特征数),不适用,时间序列预测;非线性回归,SVR是支持向量机在回归任务上的扩展。它旨在找到一个函数，使得所有训练数据点都尽可能地落在该函数的epsilon不敏感区域内，同时最小化模型的复杂度。通过核函数可以处理非线性回归问题。,人工智能;机器学习;模式识别,优点：在处理小样本、非线性及高维回归问题中表现良好。通过引入不敏感区域，对异常值不敏感。缺点：对大规模数据集训练效率不高。对缺失数据敏感。核函数的选择和参数调整对性能影响大。
A158,Lasso回归,Lasso Regression,机器学习,回归;特征选择,O(迭代次数 * 特征数 * 样本数),O(特征数),不适用,特征选择;稀疏模型;高维数据回归,Lasso回归（Least Absolute Shrinkage and Selection Operator）是一种线性回归的正则化方法。它在损失函数中添加了L1正则项，L1正则项会使得一些特征的系数变为0，从而实现特征选择，生成稀疏模型。适用于高维数据。,人工智能;机器学习;统计学;数据挖掘,优点：能够进行特征选择，生成稀疏模型，提高模型的可解释性。对高维数据表现良好。缺点：当存在高度相关的特征时，Lasso倾向于只选择其中一个。
A163,朴素贝叶斯回归,Naive Bayes Regression,机器学习,回归,训练O(样本数 * 特征数)，预测O(特征数),O(特征数 * 类别数),不适用,连续值预测(不常用),朴素贝叶斯回归是朴素贝叶斯分类器在回归任务上的扩展，但不如分类常用。它通常假设连续特征服从高斯分布，然后利用贝叶斯定理进行预测。每个特征的条件独立性假设依然存在。,人工智能;机器学习;统计学,优点：算法简单，实现快速。缺点：“朴素”假设在回归问题中通常不成立，导致预测精度不高。不如其他回归算法常用。
A164,贝叶斯线性回归,Bayesian Linear Regression,机器学习,回归;概率模型,O(特征数^3),O(特征数^2),不适用,小样本回归;不确定性量化,贝叶斯线性回归是一种概率模型，它将模型参数视为随机变量，并对参数的后验分布进行推断。通过引入先验分布，可以更好地处理小样本数据和过拟合问题，并且能够量化预测的不确定性。,人工智能;机器学习;统计学,优点：能够量化预测的不确定性。在小样本数据上表现良好。通过引入先验信息可以有效防止过拟合。缺点：计算成本相对较高，尤其是在高维数据上。需要选择合适的先验分布。
A165,高斯过程回归,Gaussian Process Regression (GPR),机器学习,回归;概率模型,O(样本数^3),O(样本数^2),不适用,小样本回归;不确定性量化;优化,高斯过程回归是一种非参数的贝叶斯回归方法。它假设函数值服从高斯过程，通过核函数来定义函数之间的相似性。GPR不仅给出预测均值，还能给出预测方差，从而量化预测的不确定性。适用于小样本数据和非线性关系。,人工智能;机器学习;统计学;优化,优点：能够量化预测的不确定性。在小样本数据上表现出色。可以处理非线性关系。缺点：计算成本高，时间复杂度为O(N^3)，不适用于大规模数据集。核函数的选择对性能影响大。
A166,决策树分类,Decision Tree Classification,机器学习,分类,O(特征数 * 样本数 * log 样本数),O(树的深度),不适用,客户流失预测;医疗诊断;信用风险评估,决策树分类是决策树在分类任务上的应用。它通过递归地将数据集划分为更小的子区域，每个子区域的预测类别是该区域内样本数量最多的类别。通过信息增益、信息增益比或基尼指数来选择最佳分裂点。,人工智能;机器学习;数据挖掘,优点：模型易于理解和解释，可视化强。可以处理数值型和类别型数据。训练速度快。缺点：容易过拟合，尤其是在数据量小或特征复杂时。对数据中的噪声敏感。决策边界是轴平行的。
A167,随机森林分类,Random Forest Classification,机器学习,分类,训练O(N_trees * 特征数 * 样本数 * log 样本数)，预测O(N_trees * 树的深度),O(N_trees * 树的深度),不适用,图像识别;医学诊断;金融欺诈检测,随机森林分类是随机森林在分类任务上的应用。它通过集成多棵决策树，每棵树独立进行分类，最终通过投票决定样本的类别。这有助于提高模型的泛化能力和鲁棒性。,人工智能;机器学习;数据挖掘,优点：泛化能力强，不易过拟合。对高维数据和缺失数据有较好的处理能力。训练速度快，可并行化。缺点：模型可解释性不如单棵决策树。在某些特定问题上，可能不如SVM或神经网络。
A168,支持向量机分类,Support Vector Machine Classification,机器学习,分类,训练O(n^2)到O(n^3)，预测O(维度),O(特征数),不适用,文本分类;图像识别;生物信息学,支持向量机分类是SVM在分类任务上的应用。其基本思想是找到一个超平面，使得不同类别的样本点被最大间隔地分开。对于非线性可分数据，通过核函数将数据映射到高维空间，使其在高维空间中线性可分。,人工智能;机器学习;模式识别,优点：在处理小样本、非线性及高维模式识别问题中表现出许多特有的优势。泛化能力强，不易过拟合。缺点：对大规模数据集训练效率不高。对缺失数据敏感。核函数的选择和参数调整对性能影响大。多分类问题需要额外策略。
A169,K-近邻分类,K-Nearest Neighbors Classification,机器学习,分类,训练O(1)，预测O(N*维度),O(N*维度),不适用,推荐系统;手写数字识别;图像分类,K-近邻分类是KNN在分类任务上的应用。在预测时，它通过计算待预测样本与训练集中所有样本的距离，找出距离最近的K个邻居，然后根据这K个邻居的多数投票来决定待预测样本的类别。,人工智能;机器学习;模式识别,优点：算法简单，易于理解和实现。无需训练过程，适用于懒惰学习。对异常值不敏感。缺点：计算复杂度高，尤其是在大规模数据集上。对特征维度敏感，高维数据下性能下降（维度灾难）。需要合适的K值和距离度量。
A170,朴素贝叶斯分类,Naive Bayes Classification,机器学习,分类,训练O(样本数 * 特征数)，预测O(特征数),O(特征数 * 类别数),不适用,文本分类;垃圾邮件过滤;情感分析,朴素贝叶斯分类器是一种基于贝叶斯定理和特征条件独立性假设的概率分类器。它假设给定类别的情况下，特征之间是相互独立的（“朴素”假设）。通过计算每个类别下每个特征的条件概率，然后利用贝叶斯公式计算后验概率，选择后验概率最大的类别作为预测结果。,人工智能;机器学习;自然语言处理,优点：算法简单，易于实现。训练速度快，在处理大规模文本数据时表现良好。在数据量较少的情况下也能有不错的表现。缺点：“朴素”假设在现实世界中往往不成立，可能导致分类精度下降。对输入数据的形式敏感。
A171,线性判别分析分类,Linear Discriminant Analysis Classification,机器学习,分类;降维,O(特征数^2 * 样本数),O(特征数^2),不适用,分类;人脸识别,LDA分类是一种有监督的分类和降维方法。它旨在找到一个投影方向，使得不同类别的数据点投影后尽可能分开，而同一类别的数据点投影后尽可能聚集。然后，在新空间中进行分类。,人工智能;机器学习;模式识别;生物信息学,优点：能够有效进行有监督降维，提高分类器的性能。在人脸识别等领域有广泛应用。缺点：对数据分布有一定假设（如高斯分布）。只能处理线性可分的问题。
A172,二次判别分析分类,Quadratic Discriminant Analysis Classification,机器学习,分类,O(特征数^2 * 样本数),O(特征数^2),不适用,分类,QDA（Quadratic Discriminant Analysis）是LDA的一种扩展，它不再假设不同类别具有相同的协方差矩阵，而是允许每个类别有其独立的协方差矩阵。这使得QDA能够处理非线性的分类边界。,人工智能;机器学习;模式识别,优点：能够处理非线性的分类边界，比LDA更灵活。缺点：参数数量更多，更容易过拟合，尤其是在数据量不足时。计算成本更高。

A178,XGBoost分类,XGBoost Classification,机器学习,集成学习,O(迭代次数 * 特征数 * 样本数 * log 样本数),O(树的数量 * 树的深度),不适用,分类;欺诈检测;客户流失预测,XGBoost分类是XGBoost在分类任务上的应用。它在梯度提升决策树的基础上进行了多项优化，包括正则化、并行处理、缺失值处理、剪枝等，使其在分类任务中表现出色。,人工智能;机器学习;数据挖掘;金融,优点：性能卓越，在许多结构化数据分类任务中是最好的算法之一。支持并行计算，训练速度快。内置正则化，有效防止过拟合。可以处理缺失值。缺点：模型可解释性相对较差。对内存要求较高。
A179,LightGBM分类,LightGBM Classification,机器学习,集成学习,O(迭代次数 * 特征数 * 样本数),O(树的数量 * 树的深度),不适用,分类;大规模数据分类,LightGBM分类是LightGBM在分类任务上的应用。它采用了基于直方图的决策树算法、GOSS和EFB等技术，大大提高了训练速度和内存效率，使其在大规模分类任务中表现出色。,人工智能;机器学习;数据挖掘;大数据,优点：训练速度极快，内存占用低，尤其适用于大规模数据集。在许多任务中性能与XGBoost相当甚至更优。支持并行和GPU训练。缺点：对稀疏数据处理可能不如XGBoost。可能会在小数据集上过拟合。
A180,CatBoost分类,CatBoost Classification,机器学习,集成学习,O(迭代次数 * 特征数 * 样本数 * log 样本数),O(树的数量 * 树的深度),不适用,分类;类别型特征处理,CatBoost分类是CatBoost在分类任务上的应用。其主要特点是能够自动处理类别型特征，并且在训练过程中采用对称树和有序提升来减少预测偏移，从而提高模型质量和泛化能力。,人工智能;机器学习;数据挖掘,优点：自动处理类别型特征，无需手动进行One-Hot编码等预处理。内置防过拟合机制，模型泛化能力强。训练速度快，性能优异。缺点：对内存要求较高。参数调优相对复杂。
A181,感知机,Perceptron,机器学习,分类,O(迭代次数 * 样本数 * 特征数),O(特征数),不适用,线性二分类,感知机是神经网络和支持向量机的基础，是一种最简单的二分类线性分类模型。它通过迭代地调整权重和偏置，找到一个能够将训练数据线性可分的超平面。如果数据线性可分，感知机算法保证收敛。,人工智能;机器学习,优点：算法简单，易于理解和实现。对于线性可分的数据，能够找到一个分离超平面。缺点：只能处理线性可分的问题。对于非线性可分的数据，算法不会收敛。对噪声敏感。
A182,多层感知机,Multilayer Perceptron (MLP),机器学习,神经网络,O(迭代次数 * 样本数 * 网络参数量),O(网络参数量),不适用,分类;回归;模式识别,多层感知机是一种前馈神经网络，由至少一个输入层、一个或多个隐藏层和一个输出层组成。层与层之间通过全连接方式连接，并使用非线性激活函数。通过反向传播算法进行训练，能够学习复杂的非线性映射关系。,人工智能;机器学习;深度学习,优点：能够学习复杂的非线性映射关系，适用于各种分类和回归任务。缺点：容易过拟合。对超参数（层数、神经元数、学习率等）敏感。训练速度可能较慢。
A183,径向基函数网络,Radial Basis Function Network (RBFN),机器学习,神经网络,O(样本数 * 隐藏层神经元数),O(隐藏层神经元数),不适用,分类;回归;函数逼近,RBFN是一种前馈神经网络，其隐藏层神经元使用径向基函数作为激活函数（如高斯核函数）。每个隐藏层神经元计算输入与中心点之间的距离，并将其映射到输出。输出层是隐藏层输出的线性组合。常用于函数逼近和模式识别。,人工智能;机器学习;模式识别,优点：具有良好的局部逼近能力。训练速度通常比MLP快。缺点：隐藏层神经元的中心点和宽度选择对性能影响大。对高维数据可能效率不高。
A184,Hopfield网络,Hopfield Network,机器学习,神经网络,O(迭代次数 * 神经元数),O(神经元数^2),不适用,联想记忆;优化问题,Hopfield网络是一种递归神经网络，用作联想记忆系统和解决优化问题。它是一个全连接的网络，神经元状态是二值的，连接权重是对称的。网络通过迭代更新神经元状态，最终收敛到一个稳定的模式（记忆）。,人工智能;机器学习;神经网络,优点：能够实现联想记忆，具有鲁棒性。可以用于解决组合优化问题。缺点：容量有限，记忆模式数量受限。容易陷入局部最优。
A185,Kohonen自组织映射,Self-Organizing Map (SOM),机器学习,神经网络;聚类,O(迭代次数 * 样本数 * 神经元数),O(神经元数 * 维度),不适用,数据可视化;聚类;模式识别,SOM是一种无监督神经网络，用于将高维数据映射到低维（通常是二维）网格状的神经元上，同时保留数据的拓扑结构。它通过竞争学习和邻域更新来调整神经元权重，使得相似的输入数据激活相邻的神经元。常用于数据可视化和聚类。,人工智能;机器学习;神经网络;数据可视化,优点：能够将高维数据映射到低维空间，便于可视化。能够发现数据中的聚类结构。缺点：训练过程需要大量迭代。对初始权重和学习率敏感。
A186,遗传算法优化,Genetic Algorithm Optimization,优化算法,启发式搜索;仿生算法,多变,多变,不适用,组合优化;机器学习参数优化;工程设计,遗传算法是一种模拟自然选择和遗传机制的全局优化算法。它通过模拟生物进化过程中的选择、交叉和变异等操作，迭代地改进解的种群，最终收敛到最优解或近似最优解。适用于解决复杂的优化问题。,计算机科学;人工智能;机器学习;运筹学,优点：能够处理复杂的、非线性的、多模态的优化问题，不依赖于梯度信息。具有全局搜索能力，可以避免陷入局部最优。缺点：收敛速度可能较慢。参数选择（种群大小、交叉率、变异率等）对性能影响大，需要经验调整。不保证找到全局最优解，通常是近似最优解。
A187,模拟退火优化,Simulated Annealing Optimization,优化算法,启发式搜索,多变,多变,不适用,组合优化;VLSI设计;图像处理,模拟退火算法是一种基于物理退火过程的启发式搜索算法，用于解决组合优化问题。它从一个随机初始解开始，通过随机扰动生成新解。与贪心算法不同，它以一定的概率接受较差的解，从而跳出局部最优，随着“温度”的降低，接受较差解的概率逐渐减小，最终收敛到全局最优解或近似最优解。,计算机科学;人工智能;机器学习;运筹学,优点：能够跳出局部最优，具有全局搜索能力。适用于解决复杂的组合优化问题，不依赖于梯度信息。缺点：收敛速度可能较慢。参数（初始温度、降温速率、迭代次数等）的选择对性能影响大，需要经验调整。不保证找到全局最优解。
A188,蚁群优化,Ant Colony Optimization,优化算法,启发式搜索;仿生算法,多变,多变,不适用,旅行商问题;路径规划;网络路由,蚁群算法是一种模拟蚂蚁觅食行为的启发式优化算法。蚂蚁在寻找食物时会释放信息素，其他蚂蚁会倾向于沿着信息素浓度高的路径前进。算法通过模拟信息素的积累和挥发过程，最终找到最优路径。适用于解决组合优化问题。,计算机科学;人工智能;机器学习;运筹学,优点：具有分布式计算的特点，鲁棒性强，能够处理动态问题。适用于解决旅行商问题等复杂的组合优化问题。缺点：收敛速度可能较慢。参数选择（信息素挥发率、信息素增加量等）对性能影响大。
A189,粒子群优化,Particle Swarm Optimization,优化算法,启发式搜索;仿生算法,多变,多变,不适用,函数优化;机器学习参数优化;图像处理,粒子群优化算法是一种模拟鸟群觅食行为的启发式优化算法。它将每个候选解看作一个在搜索空间中飞行的“粒子”，每个粒子根据其自身找到的最佳位置和整个群体找到的最佳位置来调整其飞行速度和位置，从而逐步逼近最优解。,计算机科学;人工智能;机器学习;优化,优点：算法简单，易于实现，参数较少。收敛速度相对较快。适用于解决连续函数优化问题。缺点：容易陷入局部最优，尤其是在高维复杂问题中。对参数选择敏感。
A190,差分进化,Differential Evolution (DE),优化算法,启发式搜索;进化算法,多变,多变,不适用,函数优化;机器学习参数优化,差分进化算法是一种简单而高效的全局优化算法，属于进化算法的一种。它通过差分向量的加权和来生成新的候选解，并通过选择操作来保留更好的解。适用于解决连续空间的优化问题。,计算机科学;人工智能;机器学习;优化,优点：算法简单，易于实现。对参数设置不敏感，鲁棒性强。适用于解决连续优化问题。缺点：收敛速度可能较慢。
A191,人工蜂群算法,Artificial Bee Colony (ABC),优化算法,启发式搜索;仿生算法,多变,多变,不适用,函数优化;组合优化,人工蜂群算法是一种模拟蜜蜂采蜜行为的启发式优化算法。它将蜜蜂群分为三种角色：雇佣蜂、观察蜂和侦察蜂，通过模拟这些蜜蜂的采蜜过程来寻找最优解。适用于解决连续和组合优化问题。,计算机科学;人工智能;机器学习;优化,优点：算法简单，易于实现。具有较强的全局搜索能力。缺点：收敛速度可能较慢。
A192,细菌觅食优化,Bacterial Foraging Optimization (BFO),优化算法,启发式搜索;仿生算法,多变,多变,不适用,函数优化;组合优化,细菌觅食优化算法是一种模拟大肠杆菌觅食行为的启发式优化算法。它通过模拟细菌的趋化性（Chemotaxis）、繁殖（Reproduction）和迁徙（Elimination-Dispersal）等行为来寻找最优解。适用于解决非线性、非连续、不可微的优化问题。,计算机科学;人工智能;机器学习;优化,优点：具有较强的全局搜索能力。适用于解决复杂的非线性优化问题。缺点：算法相对复杂，参数较多。
A193,和声搜索,Harmony Search (HS),优化算法,启发式搜索;仿生算法,多变,多变,不适用,函数优化;组合优化,和声搜索算法是一种模拟音乐家即兴创作过程的启发式优化算法。它通过模拟音乐家在演奏时调整音高来寻找最佳和声，从而在搜索空间中寻找最优解。适用于解决连续和组合优化问题。,计算机科学;人工智能;机器学习;优化,优点：算法简单，易于实现。参数较少。缺点：收敛速度可能较慢。
A194,灰狼优化,Grey Wolf Optimizer (GWO),优化算法,启发式搜索;仿生算法,多变,多变,不适用,函数优化;组合优化,灰狼优化算法是一种模拟灰狼捕食行为的启发式优化算法。它模拟了灰狼的社会等级制度和捕食过程（搜索、包围、攻击猎物）来寻找最优解。适用于解决连续和组合优化问题。,计算机科学;人工智能;机器学习;优化,优点：算法简单，易于实现。收敛速度相对较快。缺点：容易陷入局部最优。
A195,鲸鱼优化算法,Whale Optimization Algorithm (WOA),优化算法,启发式搜索;仿生算法,多变,多变,不适用,函数优化;组合优化,鲸鱼优化算法是一种模拟座头鲸捕食行为的启发式优化算法。它模拟了座头鲸的“气泡网捕食策略”，包括包围猎物、气泡网攻击和搜索猎物三个阶段来寻找最优解。适用于解决连续和组合优化问题。,计算机科学;人工智能;机器学习;优化,优点：算法简单，易于实现。收敛速度相对较快。缺点：容易陷入局部最优。
A196,群智能算法,Swarm Intelligence Algorithms,优化算法,启发式搜索;仿生算法,多变,多变,不适用,组合优化;函数优化,群智能算法是一类模拟自然界中生物群体行为（如鸟群、鱼群、蚁群等）的启发式优化算法。它们通过个体之间的简单交互和信息共享，涌现出解决复杂问题的集体智能。包括粒子群优化、蚁群算法、蜂群算法等。,计算机科学;人工智能;机器学习;优化,优点：具有全局搜索能力，能够避免陷入局部最优。鲁棒性强，适用于解决复杂的优化问题。缺点：收敛速度可能较慢。参数选择对性能影响大。